{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1bc2661",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f37fc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n",
      "Cloning into 'mlproduction'...\n",
      "remote: Enumerating objects: 353, done.\u001b[K\n",
      "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
      "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
      "remote: Total 353 (delta 13), reused 29 (delta 10), pack-reused 317 (from 1)\u001b[K\n",
      "Receiving objects: 100% (353/353), 3.58 MiB | 14.03 MiB/s, done.\n",
      "Resolving deltas: 100% (201/201), done.\n",
      "/kaggle/working/mlproduction\n",
      "main.py  pyproject.toml  README.md  runtime  scripts  sqls  src  uv.lock\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/\n",
    "%rm -rf mlproduction\n",
    "!git clone https://github.com/daoanhkhoa123/mlproduction.git\n",
    "%cd /kaggle/working/mlproduction\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cafd8765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: uv in /usr/local/lib/python3.11/dist-packages (0.9.18)\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m69 packages\u001b[0m \u001b[2min 378ms\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[32m# This file was autogenerated by uv via the following command:\u001b[39m\n",
      "\u001b[32m#    uv pip compile pyproject.toml -o requirements.txt --extra-index-url https://pypi.org/simple --emit-index-url\u001b[39m\n",
      "--index-url https://pypi.org/simple\n",
      "--extra-index-url https://pypi.org/simple\n",
      "\n",
      "aiohappyeyeballs==2.6.1\n",
      "\u001b[32m    # via aiohttp\u001b[39m\n",
      "aiohttp==3.13.2\n",
      "\u001b[32m    # via fsspec\u001b[39m\n",
      "aiosignal==1.4.0\n",
      "\u001b[32m    # via aiohttp\u001b[39m\n",
      "annotated-types==0.7.0\n",
      "\u001b[32m    # via pydantic\u001b[39m\n",
      "attrs==25.4.0\n",
      "\u001b[32m    # via aiohttp\u001b[39m\n",
      "certifi==2025.11.12\n",
      "\u001b[32m    # via requests\u001b[39m\n",
      "charset-normalizer==3.4.4\n",
      "\u001b[32m    # via requests\u001b[39m\n",
      "filelock==3.20.1\n",
      "\u001b[32m    # via\n",
      "    #   huggingface-hub\n",
      "    #   torch\n",
      "    #   transformers\u001b[39m\n",
      "frozenlist==1.8.0\n",
      "\u001b[32m    # via\n",
      "    #   aiohttp\n",
      "    #   aiosignal\u001b[39m\n",
      "fsspec==2025.12.0\n",
      "\u001b[32m    # via\n",
      "    #   huggingface-hub\n",
      "    #   lightning\n",
      "    #   pytorch-lightning\n",
      "    #   torch\u001b[39m\n",
      "hf-xet==1.2.0\n",
      "\u001b[32m    # via huggingface-hub\u001b[39m\n",
      "huggingface-hub==0.36.0\n",
      "\u001b[32m    # via\n",
      "    #   tokenizers\n",
      "    #   transformers\u001b[39m\n",
      "idna==3.11\n",
      "\u001b[32m    # via\n",
      "    #   requests\n",
      "    #   yarl\u001b[39m\n",
      "isort==7.0.0\n",
      "\u001b[32m    # via mlproduction (pyproject.toml)\u001b[39m\n",
      "jinja2==3.1.6\n",
      "\u001b[32m    # via torch\u001b[39m\n",
      "joblib==1.5.3\n",
      "\u001b[32m    # via scikit-learn\u001b[39m\n",
      "lightning==2.6.0\n",
      "\u001b[32m    # via mlproduction (pyproject.toml)\u001b[39m\n",
      "lightning-utilities==0.15.2\n",
      "\u001b[32m    # via\n",
      "    #   lightning\n",
      "    #   pytorch-lightning\n",
      "    #   torchmetrics\u001b[39m\n",
      "markupsafe==3.0.2\n",
      "\u001b[32m    # via\n",
      "    #   mlproduction (pyproject.toml)\n",
      "    #   jinja2\u001b[39m\n",
      "mpmath==1.3.0\n",
      "\u001b[32m    # via sympy\u001b[39m\n",
      "multidict==6.7.0\n",
      "\u001b[32m    # via\n",
      "    #   aiohttp\n",
      "    #   yarl\u001b[39m\n",
      "networkx==3.6.1\n",
      "\u001b[32m    # via torch\u001b[39m\n",
      "numpy==1.26.4\n",
      "\u001b[32m    # via\n",
      "    #   mlproduction (pyproject.toml)\n",
      "    #   pandas\n",
      "    #   scikit-learn\n",
      "    #   scipy\n",
      "    #   torchmetrics\n",
      "    #   transformers\u001b[39m\n",
      "nvidia-cublas-cu12==12.8.4.1\n",
      "\u001b[32m    # via\n",
      "    #   nvidia-cudnn-cu12\n",
      "    #   nvidia-cusolver-cu12\n",
      "    #   torch\u001b[39m\n",
      "nvidia-cuda-cupti-cu12==12.8.90\n",
      "\u001b[32m    # via torch\u001b[39m\n",
      "nvidia-cuda-nvrtc-cu12==12.8.93\n",
      "\u001b[32m    # via torch\u001b[39m\n",
      "nvidia-cuda-runtime-cu12==12.8.90\n",
      "\u001b[32m    # via torch\u001b[39m\n",
      "nvidia-cudnn-cu12==9.10.2.21\n",
      "\u001b[32m    # via torch\u001b[39m\n",
      "nvidia-cufft-cu12==11.3.3.83\n",
      "\u001b[32m    # via torch\u001b[39m\n",
      "nvidia-cufile-cu12==1.13.1.3\n",
      "\u001b[32m    # via torch\u001b[39m\n",
      "nvidia-curand-cu12==10.3.9.90\n",
      "\u001b[32m    # via torch\u001b[39m\n",
      "nvidia-cusolver-cu12==11.7.3.90\n",
      "\u001b[32m    # via torch\u001b[39m\n",
      "nvidia-cusparse-cu12==12.5.8.93\n",
      "\u001b[32m    # via\n",
      "    #   nvidia-cusolver-cu12\n",
      "    #   torch\u001b[39m\n",
      "nvidia-cusparselt-cu12==0.7.1\n",
      "\u001b[32m    # via torch\u001b[39m\n",
      "nvidia-nccl-cu12==2.27.5\n",
      "\u001b[32m    # via torch\u001b[39m\n",
      "nvidia-nvjitlink-cu12==12.8.93\n",
      "\u001b[32m    # via\n",
      "    #   nvidia-cufft-cu12\n",
      "    #   nvidia-cusolver-cu12\n",
      "    #   nvidia-cusparse-cu12\n",
      "    #   torch\u001b[39m\n",
      "nvidia-nvshmem-cu12==3.3.20\n",
      "\u001b[32m    # via torch\u001b[39m\n",
      "nvidia-nvtx-cu12==12.8.90\n",
      "\u001b[32m    # via torch\u001b[39m\n",
      "packaging==25.0\n",
      "\u001b[32m    # via\n",
      "    #   huggingface-hub\n",
      "    #   lightning\n",
      "    #   lightning-utilities\n",
      "    #   pytorch-lightning\n",
      "    #   torchmetrics\n",
      "    #   transformers\u001b[39m\n",
      "pandas==2.2.2\n",
      "\u001b[32m    # via mlproduction (pyproject.toml)\u001b[39m\n",
      "propcache==0.4.1\n",
      "\u001b[32m    # via\n",
      "    #   aiohttp\n",
      "    #   yarl\u001b[39m\n",
      "pydantic==2.12.5\n",
      "\u001b[32m    # via pydantic-settings\u001b[39m\n",
      "pydantic-core==2.41.5\n",
      "\u001b[32m    # via pydantic\u001b[39m\n",
      "pydantic-settings==2.12.0\n",
      "\u001b[32m    # via mlproduction (pyproject.toml)\u001b[39m\n",
      "python-dateutil==2.9.0.post0\n",
      "\u001b[32m    # via pandas\u001b[39m\n",
      "python-dotenv==1.2.1\n",
      "\u001b[32m    # via pydantic-settings\u001b[39m\n",
      "pytorch-lightning==2.6.0\n",
      "\u001b[32m    # via lightning\u001b[39m\n",
      "pytz==2025.2\n",
      "\u001b[32m    # via pandas\u001b[39m\n",
      "pyyaml==6.0.3\n",
      "\u001b[32m    # via\n",
      "    #   huggingface-hub\n",
      "    #   lightning\n",
      "    #   pytorch-lightning\n",
      "    #   transformers\u001b[39m\n",
      "regex==2025.11.3\n",
      "\u001b[32m    # via transformers\u001b[39m\n",
      "requests==2.32.5\n",
      "\u001b[32m    # via\n",
      "    #   huggingface-hub\n",
      "    #   transformers\u001b[39m\n",
      "safetensors==0.7.0\n",
      "\u001b[32m    # via transformers\u001b[39m\n",
      "scikit-learn==1.5.2\n",
      "\u001b[32m    # via mlproduction (pyproject.toml)\u001b[39m\n",
      "scipy==1.16.3\n",
      "\u001b[32m    # via scikit-learn\u001b[39m\n",
      "setuptools==80.9.0\n",
      "\u001b[32m    # via lightning-utilities\u001b[39m\n",
      "six==1.17.0\n",
      "\u001b[32m    # via python-dateutil\u001b[39m\n",
      "sympy==1.14.0\n",
      "\u001b[32m    # via torch\u001b[39m\n",
      "threadpoolctl==3.6.0\n",
      "\u001b[32m    # via scikit-learn\u001b[39m\n",
      "tokenizers==0.22.1\n",
      "\u001b[32m    # via transformers\u001b[39m\n",
      "torch==2.9.1\n",
      "\u001b[32m    # via\n",
      "    #   mlproduction (pyproject.toml)\n",
      "    #   lightning\n",
      "    #   pytorch-lightning\n",
      "    #   torchmetrics\u001b[39m\n",
      "torchmetrics==1.8.2\n",
      "\u001b[32m    # via\n",
      "    #   lightning\n",
      "    #   pytorch-lightning\u001b[39m\n",
      "tqdm==4.67.1\n",
      "\u001b[32m    # via\n",
      "    #   mlproduction (pyproject.toml)\n",
      "    #   huggingface-hub\n",
      "    #   lightning\n",
      "    #   pytorch-lightning\n",
      "    #   transformers\u001b[39m\n",
      "transformers==4.57.3\n",
      "\u001b[32m    # via mlproduction (pyproject.toml)\u001b[39m\n",
      "triton==3.5.1\n",
      "\u001b[32m    # via torch\u001b[39m\n",
      "typing-extensions==4.15.0\n",
      "\u001b[32m    # via\n",
      "    #   aiosignal\n",
      "    #   huggingface-hub\n",
      "    #   lightning\n",
      "    #   lightning-utilities\n",
      "    #   pydantic\n",
      "    #   pydantic-core\n",
      "    #   pytorch-lightning\n",
      "    #   torch\n",
      "    #   typing-inspection\u001b[39m\n",
      "typing-inspection==0.4.2\n",
      "\u001b[32m    # via\n",
      "    #   pydantic\n",
      "    #   pydantic-settings\u001b[39m\n",
      "tzdata==2025.3\n",
      "\u001b[32m    # via pandas\u001b[39m\n",
      "urllib3==2.6.2\n",
      "\u001b[32m    # via requests\u001b[39m\n",
      "yarl==1.22.0\n",
      "\u001b[32m    # via aiohttp\u001b[39m\n",
      "\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m69 packages\u001b[0m \u001b[2min 184ms\u001b[0m\u001b[0m\n",
      "ENV_FILE=/kaggle/working/mlproduction/.env\n",
      "Runing: uv pip install --system ipykernel\n",
      "\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 156ms\u001b[0m\u001b[0m\n",
      "Runing: uv pip install --system mlflow\n",
      "\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 161ms\u001b[0m\u001b[0m\n",
      "Runing: uv pip install --system gdown\n",
      "\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 148ms\u001b[0m\u001b[0m\n",
      "Runing: uv pip install --system pyngrok\n",
      "\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 164ms\u001b[0m\u001b[0m\n",
      "Runing: uv pip install --system dagshub\n",
      "\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 158ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!chmod +x scripts/*.sh\n",
    "!scripts/cloud_setup.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90617023",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22d93c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving folder contents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving folder 1aoddGUNcsdJuD6KtSRigVnqLW4uqeHin .ipynb_checkpoints\n",
      "Processing file 1pQevQ6Ors5DVuAXLxXiWkGh9LGi63DjE hallu_classes.csv\n",
      "Processing file 1BWfYcKTw1lBcEpeINvcsL2sW36hsadYT hallu_data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving folder contents completed\n",
      "Building directory structure\n",
      "Building directory structure completed\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1pQevQ6Ors5DVuAXLxXiWkGh9LGi63DjE\n",
      "To: /kaggle/working/mlproduction/data/hallu_classes.csv\n",
      "100%|██████████| 25.0/25.0 [00:00<00:00, 78.1kB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1BWfYcKTw1lBcEpeINvcsL2sW36hsadYT\n",
      "To: /kaggle/working/mlproduction/data/hallu_data.csv\n",
      " 44%|████▍     | 4.72M/10.7M [00:00<00:00, 27.5MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder downloaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10.7M/10.7M [00:00<00:00, 52.5MB/s]\n",
      "Download completed\n"
     ]
    }
   ],
   "source": [
    "from runtime.ultils import gdown_folder\n",
    "gdown_folder()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22aa34f",
   "metadata": {},
   "source": [
    "# What is the dog doing?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1dcafbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository mlpro doesn't exist, creating it under current user.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository mlpro doesn't exist, creating it under current user.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"ollamagena/mlpro\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"ollamagena/mlpro\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository ollamagena/mlpro initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository ollamagena/mlpro initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dagshub\n",
    "dagshub.init(repo_owner='ollamagena', repo_name='mlpro', mlflow=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11287300",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ee9b858",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'train_test_split_df' from 'src.dataloaders.ultils' (/kaggle/working/mlproduction/src/dataloaders/ultils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_79/779668955.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0multils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_label_enocder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/hallu_data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'train_test_split_df' from 'src.dataloaders.ultils' (/kaggle/working/mlproduction/src/dataloaders/ultils.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from src.dataloaders.ultils import train_test_split_df, load_label_enocder\n",
    "\n",
    "df = pd.read_csv(\"data/hallu_data.csv\")\n",
    "df.head()\n",
    "le = load_label_enocder(\"data/hallu_classes.csv\")\n",
    "X_train, X_test, y_train, y_test = train_test_split_df(df, \"label\", le, 0.3)\n",
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8be5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.preprop_svm import Preprop, prep_remove_common_words_with_counting, agg_differential\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "preprop = Preprop(prep_remove_common_words_with_counting, agg_differential)\n",
    "svc = SVC()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
