{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1bc2661",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f37fc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n",
      "Cloning into 'mlproduction'...\n",
      "remote: Enumerating objects: 389, done.\u001b[K\n",
      "remote: Counting objects: 100% (72/72), done.\u001b[K\n",
      "remote: Compressing objects: 100% (51/51), done.\u001b[K\n",
      "remote: Total 389 (delta 35), reused 53 (delta 21), pack-reused 317 (from 1)\u001b[K\n",
      "Receiving objects: 100% (389/389), 3.59 MiB | 17.02 MiB/s, done.\n",
      "Resolving deltas: 100% (223/223), done.\n",
      "/kaggle/working/mlproduction\n",
      "main.py  pyproject.toml  README.md  runtime  scripts  sqls  src  uv.lock\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/\n",
    "%rm -rf mlproduction\n",
    "!git clone https://github.com/daoanhkhoa123/mlproduction.git\n",
    "%cd /kaggle/working/mlproduction\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cafd8765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: uv in /usr/local/lib/python3.11/dist-packages (0.9.18)\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m69 packages\u001b[0m \u001b[2min 250ms\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[32m# This file was autogenerated by uv via the following command:\u001b[39m\n",
      "\u001b[32m#    uv pip compile pyproject.toml -o requirements.txt --extra-index-url https://pypi.org/simple --emit-index-url\u001b[39m\n",
      "--index-url https://pypi.org/simple\n",
      "--extra-index-url https://pypi.org/simple\n",
      "\n",
      "aiohappyeyeballs==2.6.1\n",
      "\u001b[32m    # via aiohttp\u001b[39m\n",
      "aiohttp==3.13.2\n",
      "\u001b[32m    # via fsspec\u001b[39m\n",
      "aiosignal==1.4.0\n",
      "\u001b[32m    # via aiohttp\u001b[39m\n",
      "annotated-types==0.7.0\n",
      "\u001b[32m    # via pydantic\u001b[39m\n",
      "attrs==25.4.0\n",
      "\u001b[32m    # via aiohttp\u001b[39m\n",
      "certifi==2025.11.12\n",
      "\u001b[32m    # via requests\u001b[39m\n",
      "charset-normalizer==3.4.4\n",
      "\u001b[32m    # via requests\u001b[39m\n",
      "filelock==3.20.1\n",
      "\u001b[32m    # via\n",
      "    #   huggingface-hub\n",
      "    #   torch\n",
      "    #   transformers\u001b[39m\n",
      "frozenlist==1.8.0\n",
      "\u001b[32m    # via\n",
      "    #   aiohttp\n",
      "    #   aiosignal\u001b[39m\n",
      "fsspec==2025.12.0\n",
      "\u001b[32m    # via\n",
      "    #   huggingface-hub\n",
      "    #   lightning\n",
      "    #   pytorch-lightning\n",
      "    #   torch\u001b[39m\n",
      "hf-xet==1.2.0\n",
      "\u001b[32m    # via huggingface-hub\u001b[39m\n",
      "huggingface-hub==0.36.0\n",
      "\u001b[32m    # via\n",
      "    #   tokenizers\n",
      "    #   transformers\u001b[39m\n",
      "idna==3.11\n",
      "\u001b[32m    # via\n",
      "    #   requests\n",
      "    #   yarl\u001b[39m\n",
      "isort==7.0.0\n",
      "\u001b[32m    # via mlproduction (pyproject.toml)\u001b[39m\n",
      "jinja2==3.1.6\n",
      "\u001b[32m    # via torch\u001b[39m\n",
      "joblib==1.5.3\n",
      "\u001b[32m    # via scikit-learn\u001b[39m\n",
      "lightning==2.6.0\n",
      "\u001b[32m    # via mlproduction (pyproject.toml)\u001b[39m\n",
      "lightning-utilities==0.15.2\n",
      "\u001b[32m    # via\n",
      "    #   lightning\n",
      "    #   pytorch-lightning\n",
      "    #   torchmetrics\u001b[39m\n",
      "markupsafe==3.0.2\n",
      "\u001b[32m    # via\n",
      "    #   mlproduction (pyproject.toml)\n",
      "    #   jinja2\u001b[39m\n",
      "mpmath==1.3.0\n",
      "\u001b[32m    # via sympy\u001b[39m\n",
      "multidict==6.7.0\n",
      "\u001b[32m    # via\n",
      "    #   aiohttp\n",
      "    #   yarl\u001b[39m\n",
      "networkx==3.6.1\n",
      "\u001b[32m    # via torch\u001b[39m\n",
      "numpy==1.26.4\n",
      "\u001b[32m    # via\n",
      "    #   mlproduction (pyproject.toml)\n",
      "    #   pandas\n",
      "    #   scikit-learn\n",
      "    #   scipy\n",
      "    #   torchmetrics\n",
      "    #   transformers\u001b[39m\n",
      "nvidia-cublas-cu12==12.8.4.1\n",
      "\u001b[32m    # via\n",
      "    #   nvidia-cudnn-cu12\n",
      "    #   nvidia-cusolver-cu12\n",
      "    #   torch\u001b[39m\n",
      "nvidia-cuda-cupti-cu12==12.8.90\n",
      "\u001b[32m    # via torch\u001b[39m\n",
      "nvidia-cuda-nvrtc-cu12==12.8.93\n",
      "\u001b[32m    # via torch\u001b[39m\n",
      "nvidia-cuda-runtime-cu12==12.8.90\n",
      "\u001b[32m    # via torch\u001b[39m\n",
      "nvidia-cudnn-cu12==9.10.2.21\n",
      "\u001b[32m    # via torch\u001b[39m\n",
      "nvidia-cufft-cu12==11.3.3.83\n",
      "\u001b[32m    # via torch\u001b[39m\n",
      "nvidia-cufile-cu12==1.13.1.3\n",
      "\u001b[32m    # via torch\u001b[39m\n",
      "nvidia-curand-cu12==10.3.9.90\n",
      "\u001b[32m    # via torch\u001b[39m\n",
      "nvidia-cusolver-cu12==11.7.3.90\n",
      "\u001b[32m    # via torch\u001b[39m\n",
      "nvidia-cusparse-cu12==12.5.8.93\n",
      "\u001b[32m    # via\n",
      "    #   nvidia-cusolver-cu12\n",
      "    #   torch\u001b[39m\n",
      "nvidia-cusparselt-cu12==0.7.1\n",
      "\u001b[32m    # via torch\u001b[39m\n",
      "nvidia-nccl-cu12==2.27.5\n",
      "\u001b[32m    # via torch\u001b[39m\n",
      "nvidia-nvjitlink-cu12==12.8.93\n",
      "\u001b[32m    # via\n",
      "    #   nvidia-cufft-cu12\n",
      "    #   nvidia-cusolver-cu12\n",
      "    #   nvidia-cusparse-cu12\n",
      "    #   torch\u001b[39m\n",
      "nvidia-nvshmem-cu12==3.3.20\n",
      "\u001b[32m    # via torch\u001b[39m\n",
      "nvidia-nvtx-cu12==12.8.90\n",
      "\u001b[32m    # via torch\u001b[39m\n",
      "packaging==25.0\n",
      "\u001b[32m    # via\n",
      "    #   huggingface-hub\n",
      "    #   lightning\n",
      "    #   lightning-utilities\n",
      "    #   pytorch-lightning\n",
      "    #   torchmetrics\n",
      "    #   transformers\u001b[39m\n",
      "pandas==2.2.2\n",
      "\u001b[32m    # via mlproduction (pyproject.toml)\u001b[39m\n",
      "propcache==0.4.1\n",
      "\u001b[32m    # via\n",
      "    #   aiohttp\n",
      "    #   yarl\u001b[39m\n",
      "pydantic==2.12.5\n",
      "\u001b[32m    # via pydantic-settings\u001b[39m\n",
      "pydantic-core==2.41.5\n",
      "\u001b[32m    # via pydantic\u001b[39m\n",
      "pydantic-settings==2.12.0\n",
      "\u001b[32m    # via mlproduction (pyproject.toml)\u001b[39m\n",
      "python-dateutil==2.9.0.post0\n",
      "\u001b[32m    # via pandas\u001b[39m\n",
      "python-dotenv==1.2.1\n",
      "\u001b[32m    # via pydantic-settings\u001b[39m\n",
      "pytorch-lightning==2.6.0\n",
      "\u001b[32m    # via lightning\u001b[39m\n",
      "pytz==2025.2\n",
      "\u001b[32m    # via pandas\u001b[39m\n",
      "pyyaml==6.0.3\n",
      "\u001b[32m    # via\n",
      "    #   huggingface-hub\n",
      "    #   lightning\n",
      "    #   pytorch-lightning\n",
      "    #   transformers\u001b[39m\n",
      "regex==2025.11.3\n",
      "\u001b[32m    # via transformers\u001b[39m\n",
      "requests==2.32.5\n",
      "\u001b[32m    # via\n",
      "    #   huggingface-hub\n",
      "    #   transformers\u001b[39m\n",
      "safetensors==0.7.0\n",
      "\u001b[32m    # via transformers\u001b[39m\n",
      "scikit-learn==1.5.2\n",
      "\u001b[32m    # via mlproduction (pyproject.toml)\u001b[39m\n",
      "scipy==1.16.3\n",
      "\u001b[32m    # via scikit-learn\u001b[39m\n",
      "setuptools==80.9.0\n",
      "\u001b[32m    # via lightning-utilities\u001b[39m\n",
      "six==1.17.0\n",
      "\u001b[32m    # via python-dateutil\u001b[39m\n",
      "sympy==1.14.0\n",
      "\u001b[32m    # via torch\u001b[39m\n",
      "threadpoolctl==3.6.0\n",
      "\u001b[32m    # via scikit-learn\u001b[39m\n",
      "tokenizers==0.22.1\n",
      "\u001b[32m    # via transformers\u001b[39m\n",
      "torch==2.9.1\n",
      "\u001b[32m    # via\n",
      "    #   mlproduction (pyproject.toml)\n",
      "    #   lightning\n",
      "    #   pytorch-lightning\n",
      "    #   torchmetrics\u001b[39m\n",
      "torchmetrics==1.8.2\n",
      "\u001b[32m    # via\n",
      "    #   lightning\n",
      "    #   pytorch-lightning\u001b[39m\n",
      "tqdm==4.67.1\n",
      "\u001b[32m    # via\n",
      "    #   mlproduction (pyproject.toml)\n",
      "    #   huggingface-hub\n",
      "    #   lightning\n",
      "    #   pytorch-lightning\n",
      "    #   transformers\u001b[39m\n",
      "transformers==4.57.3\n",
      "\u001b[32m    # via mlproduction (pyproject.toml)\u001b[39m\n",
      "triton==3.5.1\n",
      "\u001b[32m    # via torch\u001b[39m\n",
      "typing-extensions==4.15.0\n",
      "\u001b[32m    # via\n",
      "    #   aiosignal\n",
      "    #   huggingface-hub\n",
      "    #   lightning\n",
      "    #   lightning-utilities\n",
      "    #   pydantic\n",
      "    #   pydantic-core\n",
      "    #   pytorch-lightning\n",
      "    #   torch\n",
      "    #   typing-inspection\u001b[39m\n",
      "typing-inspection==0.4.2\n",
      "\u001b[32m    # via\n",
      "    #   pydantic\n",
      "    #   pydantic-settings\u001b[39m\n",
      "tzdata==2025.3\n",
      "\u001b[32m    # via pandas\u001b[39m\n",
      "urllib3==2.6.2\n",
      "\u001b[32m    # via requests\u001b[39m\n",
      "yarl==1.22.0\n",
      "\u001b[32m    # via aiohttp\u001b[39m\n",
      "\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m69 packages\u001b[0m \u001b[2min 158ms\u001b[0m\u001b[0m\n",
      "ENV_FILE=/kaggle/working/mlproduction/.env\n",
      "Runing: uv pip install --system ipykernel\n",
      "\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 145ms\u001b[0m\u001b[0m\n",
      "Runing: uv pip install --system mlflow\n",
      "\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 153ms\u001b[0m\u001b[0m\n",
      "Runing: uv pip install --system gdown\n",
      "\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 148ms\u001b[0m\u001b[0m\n",
      "Runing: uv pip install --system pyngrok\n",
      "\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 142ms\u001b[0m\u001b[0m\n",
      "Runing: uv pip install --system dagshub\n",
      "\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 146ms\u001b[0m\u001b[0m\n",
      "Runing: uv pip install --system sentence-transformers==4.1.0\n",
      "\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 149ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!chmod +x scripts/*.sh\n",
    "!scripts/cloud_setup.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23091d4e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'PreTrainedModel' from 'transformers' (/usr/local/lib/python3.11/dist-packages/transformers/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_79/3121127374.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msentence_transformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sentence_transformers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mexport_static_quantized_openvino_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m )\n\u001b[0;32m---> 14\u001b[0;31m from sentence_transformers.cross_encoder import (\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mCrossEncoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mCrossEncoderModelCardData\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sentence_transformers/cross_encoder/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mannotations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mCrossEncoder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCrossEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodel_card\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCrossEncoderModelCardData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCrossEncoderTrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautonotebook\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrange\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m from transformers import (\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mAutoConfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mAutoModelForSequenceClassification\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'PreTrainedModel' from 'transformers' (/usr/local/lib/python3.11/dist-packages/transformers/__init__.py)"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90617023",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22d93c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving folder contents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving folder 1aoddGUNcsdJuD6KtSRigVnqLW4uqeHin .ipynb_checkpoints\n",
      "Processing file 1pQevQ6Ors5DVuAXLxXiWkGh9LGi63DjE hallu_classes.csv\n",
      "Processing file 1BWfYcKTw1lBcEpeINvcsL2sW36hsadYT hallu_data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving folder contents completed\n",
      "Building directory structure\n",
      "Building directory structure completed\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1pQevQ6Ors5DVuAXLxXiWkGh9LGi63DjE\n",
      "To: /kaggle/working/mlproduction/data/hallu_classes.csv\n",
      "100%|██████████| 25.0/25.0 [00:00<00:00, 95.2kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder downloaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1BWfYcKTw1lBcEpeINvcsL2sW36hsadYT\n",
      "To: /kaggle/working/mlproduction/data/hallu_data.csv\n",
      "100%|██████████| 10.7M/10.7M [00:00<00:00, 81.5MB/s]\n",
      "Download completed\n"
     ]
    }
   ],
   "source": [
    "from runtime.ultils import gdown_folder\n",
    "gdown_folder()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22aa34f",
   "metadata": {},
   "source": [
    "# What is the dog doing?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1dcafbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                       <span style=\"font-weight: bold\">❗❗❗ AUTHORIZATION REQUIRED ❗❗❗</span>                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "                                       \u001b[1m❗❗❗ AUTHORIZATION REQUIRED ❗❗❗\u001b[0m                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69b013a22f754461aed98dd03a38d52f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Open the following link in your browser to authorize the client:\n",
      "https://dagshub.com/login/oauth/authorize?state=08deda0c-dba2-430e-ae83-2993622be3c4&client_id=32b60ba385aa7cecf24046d8195a71c07dd345d9657977863b52e7748e0f0f28&middleman_request_id=244189de78902645afdfa9c6a2e8ee15d6cd2db6c1c7cdfe761c516401a38e2c\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as ollamagena\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as ollamagena\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"ollamagena/mlpro\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"ollamagena/mlpro\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository ollamagena/mlpro initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository ollamagena/mlpro initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dagshub\n",
    "dagshub.init(repo_owner='ollamagena', repo_name='mlpro', mlflow=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11287300",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ee9b858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.dataloaders.ultils import train_test_split_df, load_label_enocder\n",
    "\n",
    "df = pd.read_csv(\"data/hallu_data.csv\")\n",
    "df.head()\n",
    "le = load_label_enocder(\"data/hallu_classes.csv\")\n",
    "X_train, X_test, y_train, y_test = train_test_split_df(df, \"label\", le, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e8be5de",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'cached_download' from 'huggingface_hub' (/usr/local/lib/python3.11/dist-packages/huggingface_hub/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_81/1770353411.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprop_svm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPreprop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprep_remove_common_words_with_counting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magg_differential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpreprop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPreprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep_remove_common_words_with_counting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magg_differential\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msvc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kaggle/working/mlproduction/src/models/preprop_svm.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# NOTE: this will be downloaded in runtime by cloud, i do not want to explode my computer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msentence_transformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentenceTransformer\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sentence_transformers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"2.2.2\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0m__MODEL_HUB_ORGANIZATION__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'sentence-transformers'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentencesDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParallelSentencesDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mLoggingHandler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLoggingHandler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mSentenceTransformer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sentence_transformers/datasets/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mDenoisingAutoEncoderDataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDenoisingAutoEncoderDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mNoDuplicatesDataLoader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNoDuplicatesDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mParallelSentencesDataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParallelSentencesDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mSentencesDataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentencesDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mSentenceLabelDataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentenceLabelDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sentence_transformers/datasets/ParallelSentencesDataset.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreaders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInputExample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhuggingface_hub\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHfApi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHfFolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRepository\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhf_hub_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached_download\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'cached_download' from 'huggingface_hub' (/usr/local/lib/python3.11/dist-packages/huggingface_hub/__init__.py)"
     ]
    }
   ],
   "source": [
    "from src.models.preprop_svm import Preprop, prep_remove_common_words_with_counting, agg_differential\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "preprop = Preprop(prep_remove_common_words_with_counting, agg_differential)\n",
    "svc = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f09aee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
