{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1bc2661",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0f37fc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n",
      "Cloning into 'mlproduction'...\n",
      "remote: Enumerating objects: 425, done.\u001b[K\n",
      "remote: Counting objects: 100% (108/108), done.\u001b[K\n",
      "remote: Compressing objects: 100% (74/74), done.\u001b[K\n",
      "remote: Total 425 (delta 61), reused 78 (delta 34), pack-reused 317 (from 1)\u001b[K\n",
      "Receiving objects: 100% (425/425), 3.60 MiB | 10.86 MiB/s, done.\n",
      "Resolving deltas: 100% (249/249), done.\n",
      "/kaggle/working/mlproduction\n",
      "main.py  pyproject.toml  README.md  runtime  scripts  sqls  src  uv.lock\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/\n",
    "%rm -rf mlproduction\n",
    "!git clone https://github.com/daoanhkhoa123/mlproduction.git\n",
    "%cd /kaggle/working/mlproduction\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cafd8765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: uv in /usr/local/lib/python3.11/dist-packages (0.9.18)\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m69 packages\u001b[0m \u001b[2min 342ms\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[32m# This file was autogenerated by uv via the following command:\u001b[39m\n",
      "\u001b[32m#    uv pip compile pyproject.toml -o requirements.txt --extra-index-url https://pypi.org/simple --emit-index-url\u001b[39m\n",
      "--index-url https://pypi.org/simple\n",
      "--extra-index-url https://pypi.org/simple\n",
      "\n",
      "aiohappyeyeballs==2.6.1\n",
      "\u001b[32m    # via aiohttp\u001b[39m\n",
      "aiohttp==3.13.2\n",
      "\u001b[32m    # via fsspec\u001b[39m\n",
      "aiosignal==1.4.0\n",
      "\u001b[32m    # via aiohttp\u001b[39m\n",
      "annotated-types==0.7.0\n",
      "\u001b[32m    # via pydantic\u001b[39m\n",
      "attrs==25.4.0\n",
      "\u001b[32m    # via aiohttp\u001b[39m\n",
      "certifi==2025.11.12\n",
      "\u001b[32m    # via requests\u001b[39m\n",
      "charset-normalizer==3.4.4\n",
      "\u001b[32m    # via requests\u001b[39m\n",
      "filelock==3.20.1\n",
      "\u001b[32m    # via\n",
      "    #   huggingface-hub\n",
      "    #   torch\n",
      "    #   transformers\u001b[39m\n",
      "frozenlist==1.8.0\n",
      "\u001b[32m    # via\n",
      "    #   aiohttp\n",
      "    #   aiosignal\u001b[39m\n",
      "fsspec==2025.12.0\n",
      "\u001b[32m    # via\n",
      "    #   huggingface-hub\n",
      "    #   lightning\n",
      "    #   pytorch-lightning\n",
      "    #   torch\u001b[39m\n",
      "hf-xet==1.2.0\n",
      "\u001b[32m    # via huggingface-hub\u001b[39m\n",
      "huggingface-hub==0.36.0\n",
      "\u001b[32m    # via\n",
      "    #   tokenizers\n",
      "    #   transformers\u001b[39m\n",
      "idna==3.11\n",
      "\u001b[32m    # via\n",
      "    #   requests\n",
      "    #   yarl\u001b[39m\n",
      "isort==7.0.0\n",
      "\u001b[32m    # via mlproduction (pyproject.toml)\u001b[39m\n",
      "jinja2==3.1.6\n",
      "\u001b[32m    # via torch\u001b[39m\n",
      "joblib==1.5.3\n",
      "\u001b[32m    # via scikit-learn\u001b[39m\n",
      "lightning==2.6.0\n",
      "\u001b[32m    # via mlproduction (pyproject.toml)\u001b[39m\n",
      "lightning-utilities==0.15.2\n",
      "\u001b[32m    # via\n",
      "    #   lightning\n",
      "    #   pytorch-lightning\n",
      "    #   torchmetrics\u001b[39m\n",
      "markupsafe==3.0.2\n",
      "\u001b[32m    # via\n",
      "    #   mlproduction (pyproject.toml)\n",
      "    #   jinja2\u001b[39m\n",
      "mpmath==1.3.0\n",
      "\u001b[32m    # via sympy\u001b[39m\n",
      "multidict==6.7.0\n",
      "\u001b[32m    # via\n",
      "    #   aiohttp\n",
      "    #   yarl\u001b[39m\n",
      "networkx==3.6.1\n",
      "\u001b[32m    # via torch\u001b[39m\n",
      "numpy==1.26.4\n",
      "\u001b[32m    # via\n",
      "    #   mlproduction (pyproject.toml)\n",
      "    #   pandas\n",
      "    #   scikit-learn\n",
      "    #   scipy\n",
      "    #   torchmetrics\n",
      "    #   transformers\u001b[39m\n",
      "nvidia-cublas-cu12==12.8.4.1\n",
      "\u001b[32m    # via\n",
      "    #   nvidia-cudnn-cu12\n",
      "    #   nvidia-cusolver-cu12\n",
      "    #   torch\u001b[39m\n",
      "nvidia-cuda-cupti-cu12==12.8.90\n",
      "\u001b[32m    # via torch\u001b[39m\n",
      "nvidia-cuda-nvrtc-cu12==12.8.93\n",
      "\u001b[32m    # via torch\u001b[39m\n",
      "nvidia-cuda-runtime-cu12==12.8.90\n",
      "\u001b[32m    # via torch\u001b[39m\n",
      "nvidia-cudnn-cu12==9.10.2.21\n",
      "\u001b[32m    # via torch\u001b[39m\n",
      "nvidia-cufft-cu12==11.3.3.83\n",
      "\u001b[32m    # via torch\u001b[39m\n",
      "nvidia-cufile-cu12==1.13.1.3\n",
      "\u001b[32m    # via torch\u001b[39m\n",
      "nvidia-curand-cu12==10.3.9.90\n",
      "\u001b[32m    # via torch\u001b[39m\n",
      "nvidia-cusolver-cu12==11.7.3.90\n",
      "\u001b[32m    # via torch\u001b[39m\n",
      "nvidia-cusparse-cu12==12.5.8.93\n",
      "\u001b[32m    # via\n",
      "    #   nvidia-cusolver-cu12\n",
      "    #   torch\u001b[39m\n",
      "nvidia-cusparselt-cu12==0.7.1\n",
      "\u001b[32m    # via torch\u001b[39m\n",
      "nvidia-nccl-cu12==2.27.5\n",
      "\u001b[32m    # via torch\u001b[39m\n",
      "nvidia-nvjitlink-cu12==12.8.93\n",
      "\u001b[32m    # via\n",
      "    #   nvidia-cufft-cu12\n",
      "    #   nvidia-cusolver-cu12\n",
      "    #   nvidia-cusparse-cu12\n",
      "    #   torch\u001b[39m\n",
      "nvidia-nvshmem-cu12==3.3.20\n",
      "\u001b[32m    # via torch\u001b[39m\n",
      "nvidia-nvtx-cu12==12.8.90\n",
      "\u001b[32m    # via torch\u001b[39m\n",
      "packaging==25.0\n",
      "\u001b[32m    # via\n",
      "    #   huggingface-hub\n",
      "    #   lightning\n",
      "    #   lightning-utilities\n",
      "    #   pytorch-lightning\n",
      "    #   torchmetrics\n",
      "    #   transformers\u001b[39m\n",
      "pandas==2.2.2\n",
      "\u001b[32m    # via mlproduction (pyproject.toml)\u001b[39m\n",
      "propcache==0.4.1\n",
      "\u001b[32m    # via\n",
      "    #   aiohttp\n",
      "    #   yarl\u001b[39m\n",
      "pydantic==2.12.5\n",
      "\u001b[32m    # via pydantic-settings\u001b[39m\n",
      "pydantic-core==2.41.5\n",
      "\u001b[32m    # via pydantic\u001b[39m\n",
      "pydantic-settings==2.12.0\n",
      "\u001b[32m    # via mlproduction (pyproject.toml)\u001b[39m\n",
      "python-dateutil==2.9.0.post0\n",
      "\u001b[32m    # via pandas\u001b[39m\n",
      "python-dotenv==1.2.1\n",
      "\u001b[32m    # via pydantic-settings\u001b[39m\n",
      "pytorch-lightning==2.6.0\n",
      "\u001b[32m    # via lightning\u001b[39m\n",
      "pytz==2025.2\n",
      "\u001b[32m    # via pandas\u001b[39m\n",
      "pyyaml==6.0.3\n",
      "\u001b[32m    # via\n",
      "    #   huggingface-hub\n",
      "    #   lightning\n",
      "    #   pytorch-lightning\n",
      "    #   transformers\u001b[39m\n",
      "regex==2025.11.3\n",
      "\u001b[32m    # via transformers\u001b[39m\n",
      "requests==2.32.5\n",
      "\u001b[32m    # via\n",
      "    #   huggingface-hub\n",
      "    #   transformers\u001b[39m\n",
      "safetensors==0.7.0\n",
      "\u001b[32m    # via transformers\u001b[39m\n",
      "scikit-learn==1.5.2\n",
      "\u001b[32m    # via mlproduction (pyproject.toml)\u001b[39m\n",
      "scipy==1.16.3\n",
      "\u001b[32m    # via scikit-learn\u001b[39m\n",
      "setuptools==80.9.0\n",
      "\u001b[32m    # via lightning-utilities\u001b[39m\n",
      "six==1.17.0\n",
      "\u001b[32m    # via python-dateutil\u001b[39m\n",
      "sympy==1.14.0\n",
      "\u001b[32m    # via torch\u001b[39m\n",
      "threadpoolctl==3.6.0\n",
      "\u001b[32m    # via scikit-learn\u001b[39m\n",
      "tokenizers==0.19.1\n",
      "\u001b[32m    # via transformers\u001b[39m\n",
      "torch==2.9.1\n",
      "\u001b[32m    # via\n",
      "    #   mlproduction (pyproject.toml)\n",
      "    #   lightning\n",
      "    #   pytorch-lightning\n",
      "    #   torchmetrics\u001b[39m\n",
      "torchmetrics==1.8.2\n",
      "\u001b[32m    # via\n",
      "    #   lightning\n",
      "    #   pytorch-lightning\u001b[39m\n",
      "tqdm==4.67.1\n",
      "\u001b[32m    # via\n",
      "    #   mlproduction (pyproject.toml)\n",
      "    #   huggingface-hub\n",
      "    #   lightning\n",
      "    #   pytorch-lightning\n",
      "    #   transformers\u001b[39m\n",
      "transformers==4.41.0\n",
      "\u001b[32m    # via mlproduction (pyproject.toml)\u001b[39m\n",
      "triton==3.5.1\n",
      "\u001b[32m    # via torch\u001b[39m\n",
      "typing-extensions==4.15.0\n",
      "\u001b[32m    # via\n",
      "    #   aiosignal\n",
      "    #   huggingface-hub\n",
      "    #   lightning\n",
      "    #   lightning-utilities\n",
      "    #   pydantic\n",
      "    #   pydantic-core\n",
      "    #   pytorch-lightning\n",
      "    #   torch\n",
      "    #   typing-inspection\u001b[39m\n",
      "typing-inspection==0.4.2\n",
      "\u001b[32m    # via\n",
      "    #   pydantic\n",
      "    #   pydantic-settings\u001b[39m\n",
      "tzdata==2025.3\n",
      "\u001b[32m    # via pandas\u001b[39m\n",
      "urllib3==2.6.2\n",
      "\u001b[32m    # via requests\u001b[39m\n",
      "yarl==1.22.0\n",
      "\u001b[32m    # via aiohttp\u001b[39m\n",
      "\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m69 packages\u001b[0m \u001b[2min 159ms\u001b[0m\u001b[0m\n",
      "ENV_FILE=/kaggle/working/mlproduction/.env\n",
      "Runing: uv pip install --system ipykernel\n",
      "\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 137ms\u001b[0m\u001b[0m\n",
      "Runing: uv pip install --system mlflow\n",
      "\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m91 packages\u001b[0m \u001b[2min 438ms\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 4ms\u001b[0m\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 6ms\u001b[0m\u001b[0m                                  \u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mprotobuf\u001b[0m\u001b[2m==3.20.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mprotobuf\u001b[0m\u001b[2m==6.33.2\u001b[0m\n",
      "Runing: uv pip install --system gdown\n",
      "\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 133ms\u001b[0m\u001b[0m\n",
      "Runing: uv pip install --system pyngrok\n",
      "\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 134ms\u001b[0m\u001b[0m\n",
      "Runing: uv pip install --system dagshub\n",
      "\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 139ms\u001b[0m\u001b[0m\n",
      "Runing: uv pip install --system protobuf==3.20.3\n",
      "\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m1 package\u001b[0m \u001b[2min 6ms\u001b[0m\u001b[0m                                            \u001b[0m\n",
      "\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 2ms\u001b[0m\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 3ms\u001b[0m\u001b[0m                                  \u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mprotobuf\u001b[0m\u001b[2m==6.33.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mprotobuf\u001b[0m\u001b[2m==3.20.3\u001b[0m\n",
      "Runing: uv pip install --system peft==0.10.0\n",
      "\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 138ms\u001b[0m\u001b[0m\n",
      "Runing: uv pip install --system sentence-transformers==4.1.0\n",
      "\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 138ms\u001b[0m\u001b[0m\n",
      "Runing: uv pip install --system huggingface-hub>=0.23.0<1.0\n",
      "\u001b[1m\u001b[31merror\u001b[39m\u001b[0m: Failed to parse: `huggingface-hub>=0.23.0<1.0`\n",
      "  \u001b[1m\u001b[31mCaused by\u001b[39m\u001b[0m: after parsing `0.23.0`, found `<1.0`, which is not part of a valid version\n",
      "huggingface-hub>=0.23.0<1.0\n",
      "               ^^^^^^^^^^^^\n"
     ]
    }
   ],
   "source": [
    "!chmod +x scripts/*.sh\n",
    "!scripts/cloud_setup.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90617023",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "22d93c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving folder contents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving folder 1aoddGUNcsdJuD6KtSRigVnqLW4uqeHin .ipynb_checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving folder contents completed\n",
      "Building directory structure\n",
      "Building directory structure completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 1pQevQ6Ors5DVuAXLxXiWkGh9LGi63DjE hallu_classes.csv\n",
      "Processing file 1BWfYcKTw1lBcEpeINvcsL2sW36hsadYT hallu_data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1pQevQ6Ors5DVuAXLxXiWkGh9LGi63DjE\n",
      "To: /kaggle/working/mlproduction/data/hallu_classes.csv\n",
      "100%|██████████| 25.0/25.0 [00:00<00:00, 90.5kB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1BWfYcKTw1lBcEpeINvcsL2sW36hsadYT\n",
      "To: /kaggle/working/mlproduction/data/hallu_data.csv\n",
      "100%|██████████| 10.7M/10.7M [00:00<00:00, 58.9MB/s]\n",
      "Download completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder downloaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from runtime.ultils import gdown_folder\n",
    "gdown_folder()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22aa34f",
   "metadata": {},
   "source": [
    "# What is the dog doing?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a1dcafbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"ollamagena/mlpro\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"ollamagena/mlpro\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository ollamagena/mlpro initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository ollamagena/mlpro initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dagshub\n",
    "dagshub.init(repo_owner='ollamagena', repo_name='mlpro', mlflow=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11287300",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5ee9b858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (4900, 4)\n",
      "X_test shape: (2100, 4)\n",
      "y_train shape: (4900,)\n",
      "y_test shape: (2100,)\n",
      "\n",
      "Sample rows from X_train:\n",
      "                                        id  \\\n",
      "4920  c362ad9b-e8c4-4147-964c-20ea7f4b305b   \n",
      "2944  9874108d-6a58-461e-9514-4122cfd37d58   \n",
      "\n",
      "                                                context  \\\n",
      "4920  Về lịch sử, Cuba luôn có tỷ lệ giáo dục và biế...   \n",
      "2944  Bốn quy tắc súc tích và tổng quát cho nghiên c...   \n",
      "\n",
      "                                                 prompt  \\\n",
      "4920  Trong thời gian tham gia học tập, học sinh tại...   \n",
      "2944            Newt0n dã hoan thàn phuong phap của ai?   \n",
      "\n",
      "                                               response  \n",
      "4920  Học sinh tại Cuba phải tự chi trả cho đồng phụ...  \n",
      "2944  Newton đã hoàn thiện phương pháp thực nghiệm c...  \n",
      "\n",
      "Sample values from y_train: [1 2]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from src.dataloaders.ultils import train_test_split_df, load_label_enocder\n",
    "\n",
    "df = pd.read_csv(\"data/hallu_data.csv\")\n",
    "df.head()\n",
    "le = load_label_enocder(\"data/hallu_classes.csv\")\n",
    "X_train, X_test, y_train, y_test = train_test_split_df(df, \"label\", le, 0.3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5ec48fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/9fc02da896174a8d950e6b059532f67a', creation_time=1766052189411, experiment_id='1', last_update_time=1766052189411, lifecycle_stage='active', name='embedding-sklearn2', tags={'mlflow.experimentKind': 'custom_model_development'}>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_experiment(\"embedding-sklearn2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0e8be5de",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'agg_concatenate' from 'src.models.preprop_svm' (/kaggle/working/mlproduction/src/models/preprop_svm.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_786/2596648651.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprop_svm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPreprop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprep_remove_common_words_with_counting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magg_differential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magg_concatenate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minfer_signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'agg_concatenate' from 'src.models.preprop_svm' (/kaggle/working/mlproduction/src/models/preprop_svm.py)"
     ]
    }
   ],
   "source": [
    "from src.models.preprop_svm import Preprop, prep_remove_common_words_with_counting, agg_differential, agg_concatenate\n",
    "from mlflow.models import infer_signature\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "with mlflow.start_run(run_name=\"full run with vtack aggeration and bagging SVC\"):\n",
    "    preprop_params = {\n",
    "        \"prepropfn\": prep_remove_common_words_with_counting,\n",
    "        \"aggfn\": agg_concatenate,\n",
    "        \"encoder_name\": \"bkai-foundation-models/vietnamese-bi-encoder\"\n",
    "    }\n",
    "\n",
    "    base_svc_params = {\n",
    "    \"C\": 1.0,\n",
    "    \"kernel\": \"rbf\",\n",
    "    \"probability\": False,\n",
    "    \"random_state\": 42,\n",
    "    \"decision_function_shape\": \"ovr\",\n",
    "}\n",
    "\n",
    "    bagging_params = {\n",
    "        \"n_estimators\": 10,\n",
    "        \"max_samples\": 0.8,\n",
    "        \"max_features\": 1.0,\n",
    "        \"bootstrap\": True,\n",
    "        \"n_jobs\": -1,\n",
    "        \"random_state\": 42,\n",
    "    }\n",
    "\n",
    "\n",
    "    mlflow.log_params({\n",
    "        **preprop_params,\n",
    "        **{f\"base_svc.{k}\": v for k, v in base_svc_params.items()},\n",
    "        **{f\"bagging.{k}\": v for k, v in bagging_params.items()},\n",
    "    })\n",
    "\n",
    "\n",
    "    preprop = Preprop(**preprop_params)\n",
    "    x_train_emd = preprop.call_df(X_train, column1=\"context\", column2=\"response\", batch_size= 8)\n",
    "    base_svc = SVC(**base_svc_params)\n",
    "    model = BaggingClassifier(estimator=base_svc, **bagging_params)\n",
    "    model.fit(x_train_emd, y_train)\n",
    "\n",
    "    x_test_emd = preprop.call_df(X_test, column1=\"context\", column2=\"response\", batch_size= 8)\n",
    "    y_pred = model.predict(x_test_emd)\n",
    "\n",
    "    # Calculate and log metrics\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"precision\": precision_score(y_test, y_pred, average=\"weighted\"),\n",
    "        \"recall\": recall_score(y_test, y_pred, average=\"weighted\"),\n",
    "        \"f1_score\": f1_score(y_test, y_pred, average=\"weighted\"),\n",
    "    }\n",
    "    mlflow.log_metrics(metrics)    \n",
    "\n",
    "    signature = infer_signature(x_test_emd, model.predict(x_test_emd))\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model = model,\n",
    "        name=\"svc\",\n",
    "        signature=signature,\n",
    "        input_example=x_train_emd[:5]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f09aee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
